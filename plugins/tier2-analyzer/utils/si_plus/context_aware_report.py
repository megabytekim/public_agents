"""SI+ Context-Aware ë¦¬í¬íŠ¸ ìƒì„±ê¸°

ê¸°ì¡´ ë¶„ì„ íŒŒì¼ì„ ì½ê³  ë§¥ë½ì— ë§ëŠ” ì„¼í‹°ë¨¼íŠ¸ ë¦¬í¬íŠ¸ ìƒì„±
"""

import json
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, List
from dotenv import load_dotenv

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ .env ë¡œë“œ
PROJECT_ROOT = Path(__file__).resolve().parent.parent.parent
load_dotenv(PROJECT_ROOT / ".env")
load_dotenv(Path.cwd() / ".env")

from .unified_collector import collect_all_sources
from .base import analyze_sentiment, get_sentiment_label
from .context_extractor import (
    StockContext,
    extract_context_from_analysis,
    context_to_search_config,
)


async def generate_context_aware_report(
    analysis_file: Path,
    output_dir: Optional[Path] = None,
    telegram_channels: Optional[List[str]] = None,
) -> str:
    """
    ê¸°ì¡´ ë¶„ì„ íŒŒì¼ ê¸°ë°˜ Context-Aware SI+ ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        analysis_file: stock_analyzer_summary.md ê²½ë¡œ
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ analysis_fileê³¼ ê°™ì€ ë””ë ‰í† ë¦¬)
        telegram_channels: í…”ë ˆê·¸ë¨ ì±„ë„ (ì—†ìœ¼ë©´ configì—ì„œ ë¡œë“œ)

    Returns:
        ìƒì„±ëœ ë¦¬í¬íŠ¸ ë‚´ìš©
    """
    # 1. ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
    print(f"\n{'='*60}")
    print(f"SI+ Context-Aware ë¦¬í¬íŠ¸ ìƒì„±")
    print(f"{'='*60}")
    print(f"\në¶„ì„ íŒŒì¼: {analysis_file}")

    ctx = extract_context_from_analysis(analysis_file)
    if not ctx:
        raise ValueError(f"ë¶„ì„ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {analysis_file}")

    print(f"\nì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ:")
    print(f"  ì¢…ëª©: {ctx.stock_name} ({ctx.ticker})")
    print(f"  ë³„ì¹­: {', '.join(ctx.aliases)}")
    print(f"  ì‚¬ì—… í‚¤ì›Œë“œ: {', '.join(ctx.business_keywords[:5])}...")
    print(f"  í…Œë§ˆ í‚¤ì›Œë“œ: {', '.join(ctx.theme_keywords[:5])}...")

    # 2. í…”ë ˆê·¸ë¨ ì±„ë„ ë¡œë“œ
    if telegram_channels is None:
        config_path = PROJECT_ROOT / "config" / "telegram_channels.json"
        if config_path.exists():
            with open(config_path) as f:
                config = json.load(f)
            telegram_channels = []
            for cat_data in config.get("channels", {}).values():
                telegram_channels.extend(cat_data.get("channels", []))
            print(f"  Telegram ì±„ë„: {len(telegram_channels)}ê°œ (configì—ì„œ ë¡œë“œ)")
        else:
            telegram_channels = []
            print(f"  Telegram ì±„ë„: ì—†ìŒ")

    # 3. ì„¼í‹°ë¨¼íŠ¸ ìˆ˜ì§‘
    search_config = context_to_search_config(ctx)
    print(f"\në°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    print(f"  ê²€ìƒ‰ í…Œë§ˆ: {', '.join(search_config['theme_keywords'][:8])}...")

    result = await collect_all_sources(
        ticker=search_config["ticker"],
        aliases=search_config["aliases"],
        theme_keywords=search_config["theme_keywords"],
        telegram_channels=telegram_channels,
        enable_reddit=True,
        enable_naver=True,
        limit_per_source=100,
    )

    # 4. ë¦¬í¬íŠ¸ ìƒì„±
    report = _generate_narrative_report(ctx, result)

    # 5. ì €ì¥
    if output_dir is None:
        output_dir = analysis_file.parent

    output_dir.mkdir(parents=True, exist_ok=True)
    output_path = output_dir / "SI_PLUS_REPORT.md"

    with open(output_path, "w", encoding="utf-8") as f:
        f.write(report)

    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")

    return report


def _generate_narrative_report(ctx: StockContext, result: Dict) -> str:
    """ì„œìˆ í˜• ë¦¬í¬íŠ¸ ìƒì„±"""
    lines = []
    now = datetime.now().strftime("%Y-%m-%d %H:%M")

    stats = result.get("stats", {})
    combined = result.get("combined", {})
    sentiment = combined.get("sentiment", {})
    score = sentiment.get("score", 0)
    label = combined.get("sentiment_label", "N/A")

    # í—¤ë”
    lines.append(f"# {ctx.stock_name} ({ctx.ticker}) SI+ ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„")
    lines.append("")
    lines.append(f"> ë¶„ì„ì¼: {now} KST | Context-Aware Mode")
    lines.append("")
    lines.append("---")
    lines.append("")

    # 1. Executive Summary
    lines.append("## Executive Summary")
    lines.append("")

    total_msgs = stats.get("total_messages", 0)
    direct_count = stats.get("direct_count", 0)
    theme_count = stats.get("theme_count", 0)

    bullish = sentiment.get("bullish_count", 0)
    bearish = sentiment.get("bearish_count", 0)

    if total_msgs > 0:
        lines.append(f"**{ctx.stock_name}**ì— ëŒ€í•œ ì»¤ë®¤ë‹ˆí‹° ì„¼í‹°ë¨¼íŠ¸ëŠ” **{label}** (ì ìˆ˜: {score:+.2f})ì…ë‹ˆë‹¤.")
        lines.append("")

        if direct_count > 0:
            lines.append(f"- ì¢…ëª© ì§ì ‘ ì–¸ê¸‰: **{direct_count}ê±´** (ì¢…ëª©ëª…/ì½”ë“œ ë§¤ì¹­)")
        if theme_count > 0:
            lines.append(f"- ì—°ê´€ í…Œë§ˆ ì–¸ê¸‰: **{theme_count}ê±´** ({', '.join(ctx.theme_keywords[:3])} ë“±)")
        lines.append("")

        if bullish > bearish * 2:
            lines.append("ì „ë°˜ì ìœ¼ë¡œ **ê¸ì •ì ** ë¶„ìœ„ê¸°ê°€ ìš°ì„¸í•©ë‹ˆë‹¤.")
        elif bearish > bullish * 2:
            lines.append("ì „ë°˜ì ìœ¼ë¡œ **ë¶€ì •ì ** ë¶„ìœ„ê¸°ê°€ ìš°ì„¸í•©ë‹ˆë‹¤.")
        else:
            lines.append("**ì¤‘ë¦½ì ** ë¶„ìœ„ê¸°ë¡œ, ëšœë ·í•œ ë°©í–¥ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        lines.append(f"**{ctx.stock_name}**ì— ëŒ€í•œ ì»¤ë®¤ë‹ˆí‹° ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        lines.append("")
        lines.append("- ì†Œí˜•ì£¼ íŠ¹ì„±ìƒ ê°œì¸ íˆ¬ìì ê´€ì‹¬ì´ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        lines.append("- í…Œë§ˆ í‚¤ì›Œë“œë¥¼ í†µí•œ ê°„ì ‘ ë¶„ì„ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

    lines.append("")
    lines.append("---")
    lines.append("")

    # 2. ìˆ˜ì§‘ í˜„í™©
    lines.append("## ë°ì´í„° ìˆ˜ì§‘ í˜„í™©")
    lines.append("")
    lines.append("| ì†ŒìŠ¤ | ìˆ˜ì§‘ëŸ‰ | ì§ì ‘ ë§¤ì¹­ | í…Œë§ˆ ë§¤ì¹­ |")
    lines.append("|------|--------|----------|----------|")

    for source_result in result.get("sources", []):
        source = source_result.get("source", "unknown")
        s_stats = source_result.get("stats", {})
        total = s_stats.get("total_messages", 0)
        direct = s_stats.get("direct_count", 0)
        theme = s_stats.get("theme_count", 0)
        lines.append(f"| {source.capitalize()} | {total} | {direct} | {theme} |")

    lines.append(f"| **í•©ê³„** | **{total_msgs}** | **{direct_count}** | **{theme_count}** |")
    lines.append("")
    lines.append("---")
    lines.append("")

    # 3. ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„
    lines.append("## ì„¼í‹°ë¨¼íŠ¸ ë¶„ì„")
    lines.append("")
    lines.append(f"### ì¢…í•© ì ìˆ˜: **{label}** ({score:+.2f})")
    lines.append("")

    if total_msgs > 0:
        neutral = sentiment.get("neutral_count", 0)
        lines.append("| ì˜ê²¬ | ë¹„ìœ¨ |")
        lines.append("|------|------|")
        lines.append(f"| ğŸŸ¢ ìƒìŠ¹ | {bullish/total_msgs*100:.1f}% ({bullish}ê±´) |")
        lines.append(f"| ğŸ”´ í•˜ë½ | {bearish/total_msgs*100:.1f}% ({bearish}ê±´) |")
        lines.append(f"| âšª ì¤‘ë¦½ | {neutral/total_msgs*100:.1f}% ({neutral}ê±´) |")
        lines.append("")

    lines.append("---")
    lines.append("")

    # 4. ì£¼ìš” ì˜ê²¬ (Context-aware)
    lines.append("## ì£¼ìš” ì˜ê²¬")
    lines.append("")

    top_bullish = sentiment.get("top_bullish", [])
    top_bearish = sentiment.get("top_bearish", [])

    # ì§ì ‘ ë§¤ì¹­ ìš°ì„  í‘œì‹œ
    direct_bullish = [m for m in top_bullish if m.get("match_type") == "direct"]
    direct_bearish = [m for m in top_bearish if m.get("match_type") == "direct"]

    if direct_bullish or direct_bearish:
        lines.append("### ì¢…ëª© ì§ì ‘ ì–¸ê¸‰")
        lines.append("")

        if direct_bullish:
            lines.append("**ìƒìŠ¹ ì˜ê²¬:**")
            for msg in direct_bullish[:3]:
                text = msg.get("text", "")[:60]
                source = msg.get("source", "")
                lines.append(f"- [{source}] \"{text}...\"")
            lines.append("")

        if direct_bearish:
            lines.append("**í•˜ë½ ì˜ê²¬:**")
            for msg in direct_bearish[:3]:
                text = msg.get("text", "")[:60]
                source = msg.get("source", "")
                lines.append(f"- [{source}] \"{text}...\"")
            lines.append("")

    # í…Œë§ˆ ë§¤ì¹­
    theme_bullish = [m for m in top_bullish if m.get("match_type") == "theme"]
    theme_bearish = [m for m in top_bearish if m.get("match_type") == "theme"]

    if theme_bullish or theme_bearish:
        lines.append("### ì—°ê´€ í…Œë§ˆ ë™í–¥")
        lines.append("")
        lines.append(f"ê²€ìƒ‰ í…Œë§ˆ: {', '.join(ctx.theme_keywords[:5])}")
        lines.append("")

        if theme_bullish:
            lines.append("**ê¸ì •ì  ì‹œê·¸ë„:**")
            for msg in theme_bullish[:3]:
                text = msg.get("text", "")[:60]
                kw = msg.get("matched_keyword", "")
                lines.append(f"- [{kw}] \"{text}...\"")
            lines.append("")

        if theme_bearish:
            lines.append("**ë¶€ì •ì  ì‹œê·¸ë„:**")
            for msg in theme_bearish[:3]:
                text = msg.get("text", "")[:60]
                kw = msg.get("matched_keyword", "")
                lines.append(f"- [{kw}] \"{text}...\"")
            lines.append("")

    if not (direct_bullish or direct_bearish or theme_bullish or theme_bearish):
        lines.append("_ì˜ë¯¸ ìˆëŠ” ì˜ê²¬ì´ ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤._")
        lines.append("")

    lines.append("---")
    lines.append("")

    # 5. í…Œë§ˆ íŠ¸ë Œë“œ
    lines.append("## í…Œë§ˆ íŠ¸ë Œë“œ")
    lines.append("")

    all_messages = combined.get("messages", [])
    theme_counts = {}
    for msg in all_messages:
        if msg.get("match_type") == "theme":
            kw = msg.get("matched_keyword", "ê¸°íƒ€")
            theme_counts[kw] = theme_counts.get(kw, 0) + 1

    if theme_counts:
        lines.append("| í…Œë§ˆ | ì–¸ê¸‰ ìˆ˜ | ë¹„ì¤‘ |")
        lines.append("|------|---------|------|")
        total_theme_msgs = sum(theme_counts.values())
        for kw, count in sorted(theme_counts.items(), key=lambda x: x[1], reverse=True)[:7]:
            pct = count / total_theme_msgs * 100
            lines.append(f"| {kw} | {count} | {pct:.1f}% |")
        lines.append("")

        # í…Œë§ˆ ì¸ì‚¬ì´íŠ¸
        top_theme = max(theme_counts, key=theme_counts.get)
        lines.append(f"ê°€ì¥ í™œë°œí•œ í…Œë§ˆëŠ” **{top_theme}**ë¡œ, ê´€ë ¨ ë…¼ì˜ê°€ í™œë°œí•©ë‹ˆë‹¤.")
    else:
        lines.append("_í…Œë§ˆ í‚¤ì›Œë“œ ë§¤ì¹­ ì—†ìŒ_")

    lines.append("")
    lines.append("---")
    lines.append("")

    # 6. ë£¨ë¨¸ ì²´í¬
    rumors = combined.get("rumors", [])
    rumor_ratio = stats.get("rumor_ratio", 0)

    lines.append("## ì •ë³´ ì‹ ë¢°ë„")
    lines.append("")
    lines.append(f"ë£¨ë¨¸ ë¹„ìœ¨: **{rumor_ratio:.1%}**")
    lines.append("")

    if rumor_ratio < 0.1:
        lines.append("âœ… ëŒ€ë¶€ë¶„ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì •ë³´ì…ë‹ˆë‹¤.")
    elif rumor_ratio < 0.3:
        lines.append("âš ï¸ ì¼ë¶€ í™•ì¸ë˜ì§€ ì•Šì€ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        lines.append("ğŸš¨ ë£¨ë¨¸ ë¹„ìœ¨ì´ ë†’ìŠµë‹ˆë‹¤. êµì°¨ ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    if rumors:
        lines.append("")
        lines.append("**ê²€ì¦ í•„ìš”:**")
        for r in rumors[:3]:
            text = r.get("text", "")[:50]
            lines.append(f"- \"{text}...\"")

    lines.append("")
    lines.append("---")
    lines.append("")

    # 7. ì¢…í•© íŒë‹¨ (with context)
    lines.append("## ì¢…í•© íŒë‹¨")
    lines.append("")

    lines.append("| í•­ëª© | íŒë‹¨ |")
    lines.append("|------|------|")
    lines.append(f"| ì„¼í‹°ë¨¼íŠ¸ | {label} ({score:+.2f}) |")
    lines.append(f"| ë°ì´í„° ì¶©ë¶„ì„± | {'ì¶©ë¶„' if total_msgs >= 50 else 'ë³´í†µ' if total_msgs >= 10 else 'ë¶€ì¡±'} ({total_msgs}ê±´) |")
    lines.append(f"| ì§ì ‘ ì–¸ê¸‰ ë¹„ìœ¨ | {direct_count/total_msgs*100:.1f}% |" if total_msgs > 0 else "| ì§ì ‘ ì–¸ê¸‰ ë¹„ìœ¨ | N/A |")
    lines.append(f"| ì •ë³´ ì‹ ë¢°ë„ | {'ë†’ìŒ' if rumor_ratio < 0.1 else 'ë³´í†µ' if rumor_ratio < 0.3 else 'ë‚®ìŒ'} |")
    lines.append("")

    # ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
    if ctx.summary:
        lines.append("### ê¸°ì¡´ ë¶„ì„ê³¼ì˜ ì—°ê³„")
        lines.append("")
        lines.append(f"ê¸°ì¡´ ë¶„ì„ì—ì„œëŠ” \"{ctx.summary[:100]}...\"ë¡œ í‰ê°€í–ˆìŠµë‹ˆë‹¤.")
        lines.append("")

        # ì„¼í‹°ë¨¼íŠ¸ì™€ ê¸°ì¡´ ë¶„ì„ ë¹„êµ
        if score > 0.3 and "ì ì" in ctx.summary:
            lines.append("âš ï¸ ì»¤ë®¤ë‹ˆí‹° ì„¼í‹°ë¨¼íŠ¸ëŠ” ê¸ì •ì ì´ë‚˜, ì¬ë¬´ ìƒí™©(ì ì)ê³¼ ê´´ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤.")
        elif score < -0.3 and "íšŒë³µ" in ctx.summary:
            lines.append("âš ï¸ ì»¤ë®¤ë‹ˆí‹° ì„¼í‹°ë¨¼íŠ¸ëŠ” ë¶€ì •ì ì´ë‚˜, í€ë”ë©˜í„¸ íšŒë³µ ì¡°ì§ê³¼ ê´´ë¦¬ê°€ ìˆìŠµë‹ˆë‹¤.")
        else:
            lines.append("ì„¼í‹°ë¨¼íŠ¸ê°€ ê¸°ì¡´ ë¶„ì„ ë°©í–¥ê³¼ ì¼ê´€ì„±ì´ ìˆìŠµë‹ˆë‹¤.")

    lines.append("")
    lines.append("---")
    lines.append("")
    lines.append("*Generated by SI+ Context-Aware Agent*")

    return "\n".join(lines)


# CLI ì‹¤í–‰ ì§€ì›
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python context_aware_report.py <analysis_file>")
        sys.exit(1)

    analysis_file = Path(sys.argv[1])
    asyncio.run(generate_context_aware_report(analysis_file))
