---
description: ë…¼ë¬¸ ê²€ìƒ‰ë¶€í„° ì²˜ë¦¬ê¹Œì§€ ì „ì²´ ì›Œí¬í”Œë¡œìš°. ì‚¬ìš©ë²• - /paper-research [query] --limit [N]
allowed-tools: mcp__arxiv-mcp-server, Task, Read, Write, WebFetch
argument-hint: [query] --limit [N]
---

# Paper Research - ì „ì²´ ì›Œí¬í”Œë¡œìš°

ë…¼ë¬¸ ê²€ìƒ‰ â†’ ë‹¤ìš´ë¡œë“œ â†’ Citation ì¡°íšŒ â†’ ì²˜ë¦¬ â†’ Registry ì—…ë°ì´íŠ¸ê¹Œì§€ í•œ ë²ˆì— ìˆ˜í–‰í•©ë‹ˆë‹¤.

## ì‚¬ìš©ë²•

```bash
/paper-research ordinal regression --limit 5
/paper-research ti:"survey" ordinal regression --limit 3
/paper-research "deep learning" age estimation --limit 10
```

## ì „ì²´ ì›Œí¬í”Œë¡œìš°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  /paper-research (ë©”ì¸ ì»¨í…ìŠ¤íŠ¸, MCP ì ‘ê·¼ ê°€ëŠ¥)           â”‚
â”‚                                                         â”‚
â”‚  1. arXiv ê²€ìƒ‰ (MCP)                                    â”‚
â”‚  2. Index ì¤‘ë³µ ì²´í¬ (registry-index.txt, ê²½ëŸ‰)          â”‚
â”‚  3. ë…¼ë¬¸ ë‹¤ìš´ë¡œë“œ (MCP)                                  â”‚
â”‚  4. Citation ì¡°íšŒ (Semantic Scholar)                    â”‚
â”‚  5. Slug ìƒì„±                                           â”‚
â”‚  6. ë³‘ë ¬ Task í˜¸ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚       â”œâ”€ paper-processor (ì¼ë°˜ ë…¼ë¬¸)    â”‚ ë³‘ë ¬          â”‚
â”‚       â””â”€ survey-processor (Survey)     â”‚               â”‚
â”‚  7. Registry ì—…ë°ì´íŠ¸ (2ê°œ íŒŒì¼ ë™ì‹œ!)   â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚       â”œâ”€ registry.json (ì „ì²´ ë©”íƒ€ë°ì´í„°)                â”‚
â”‚       â””â”€ registry-index.txt (IDë§Œ)                     â”‚
â”‚  8. ìµœì¢… ë³´ê³                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ì‘ì—… ìˆœì„œ

### Step 1: ì¸ì íŒŒì‹±

```python
query = " ".join(args)  # "ordinal regression"
limit = args.get("--limit", 5)
categories = args.get("--categories", ["cs.CV", "cs.LG", "cs.AI"])
```

### Step 2: Index ë¡œë“œ (ì¤‘ë³µ ì²´í¬ìš©)

> **ì»¨í…ìŠ¤íŠ¸ ìµœì í™”**: registry.json ëŒ€ì‹  ê²½ëŸ‰ index íŒŒì¼ ì‚¬ìš© (~20ë°”ì´íŠ¸/ë…¼ë¬¸)

```python
# ê²½ëŸ‰ ì¸ë±ìŠ¤ íŒŒì¼ ì½ê¸° (registry.json ëŒ€ì‹ )
index_content = Read("plugins/vehicle-contamination-or/private/registry-index.txt")
existing_ids = set()
for line in index_content.strip().split("\n"):
    line = line.strip()
    if line and not line.startswith("#"):  # ì£¼ì„ ì œì™¸
        existing_ids.add(line)
```

### Step 3: arXiv ê²€ìƒ‰

```python
results = mcp__arxiv-mcp-server__search_papers(
    query=query,
    categories=categories,
    max_results=limit * 2,  # ì¤‘ë³µ ì œê±° ëŒ€ë¹„
    sort_by="relevance"
)
```

### Step 4: ì¤‘ë³µ í•„í„°ë§

```python
new_papers = []
for paper in results["papers"]:
    paper_id = f"arxiv:{paper['id'].split('v')[0]}"
    if paper_id not in existing_ids:
        new_papers.append(paper)
        existing_ids.add(paper_id)

    if len(new_papers) >= limit:
        break

print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results['papers'])}ê°œ")
print(f"ì‹ ê·œ ë…¼ë¬¸: {len(new_papers)}ê°œ")
```

### Step 5: ê° ë…¼ë¬¸ ì¤€ë¹„ (ë‹¤ìš´ë¡œë“œ + Citation + Slug)

```python
papers_to_process = []

for paper in new_papers:
    paper_id = paper["id"].split("v")[0]  # ë²„ì „ ì œê±°

    # 5.1 ë‹¤ìš´ë¡œë“œ
    mcp__arxiv-mcp-server__download_paper(paper_id=paper_id)

    # 5.2 Citation ì¡°íšŒ
    citation_response = WebFetch(
        url=f"https://api.semanticscholar.org/graph/v1/paper/arXiv:{paper_id}?fields=citationCount",
        prompt="Extract citationCount from JSON"
    )
    citations = citation_response.citationCount or "XX"

    # 5.3 Slug ìƒì„±
    title_part = paper["title"].lower()
    title_part = re.sub(r'[^a-z0-9\s]', '', title_part)
    title_part = '-'.join(title_part.split()[:4])
    year = paper["published"][:4]
    slug = f"{title_part}-{year}-c{citations}"[:60]

    # 5.4 Survey ì—¬ë¶€ íŒë³„
    is_survey = any(word in paper["title"].lower() for word in ["survey", "review", "overview"])

    # 5.5 ë°°ì¹˜ ëª©ë¡ì— ì¶”ê°€
    papers_to_process.append({
        "id": f"arxiv:{paper_id}",
        "title": paper["title"],
        "year": int(year),
        "url": f"https://arxiv.org/abs/{paper_id}",
        "citations": citations if citations != "XX" else None,
        "slug": slug,
        "is_survey": is_survey,
        "file_path": f"~/.arxiv-mcp-server/papers/{paper_id}.md"
    })
```

### Step 6: ë³‘ë ¬ Task í˜¸ì¶œ (paper-processor / survey-processor)

> **ì¤‘ìš”**: ë‹¨ì¼ ë©”ì‹œì§€ì—ì„œ ì—¬ëŸ¬ Taskë¥¼ ë³‘ë ¬ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
> Nested Task ì œí•œìœ¼ë¡œ ì¸í•´ ì¤‘ê°„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° ì—†ì´ ì§ì ‘ í˜¸ì¶œí•©ë‹ˆë‹¤.

```python
# ë…¼ë¬¸ ìœ í˜•ë³„ ë¶„ë¥˜
survey_papers = [p for p in papers_to_process if p["is_survey"]]
regular_papers = [p for p in papers_to_process if not p["is_survey"]]

# ë³‘ë ¬ Task í˜¸ì¶œ (ë‹¨ì¼ ë©”ì‹œì§€ì— ì—¬ëŸ¬ Task)
tasks = []

for paper in regular_papers:
    tasks.append(Task(
        subagent_type="vehicle-contamination-or:paper-processor",
        description=f"Process {paper['slug'][:20]}",
        prompt=f"""
ë…¼ë¬¸ ì •ë³´:
{json.dumps(paper, indent=2, ensure_ascii=False)}

ë…¼ë¬¸ íŒŒì¼: {paper["file_path"]}

ì €ì¥ ìœ„ì¹˜:
/Users/newyork/public_agents/plugins/vehicle-contamination-or/private/paper/{paper["slug"]}/summary.md

ìœ„ ìœ„ì¹˜ì— summary.mdë¥¼ ìƒì„±í•˜ì„¸ìš”.
ì™„ë£Œ í›„ ê²°ê³¼ JSON ë°˜í™˜: {{"success": true, "slug": "{paper['slug']}"}}
"""
    ))

for paper in survey_papers:
    tasks.append(Task(
        subagent_type="vehicle-contamination-or:survey-processor",
        description=f"Process survey {paper['slug'][:20]}",
        prompt=f"""
ë…¼ë¬¸ ì •ë³´:
{json.dumps(paper, indent=2, ensure_ascii=False)}

ë…¼ë¬¸ íŒŒì¼: {paper["file_path"]}

ì €ì¥ ìœ„ì¹˜:
/Users/newyork/public_agents/plugins/vehicle-contamination-or/private/paper/{paper["slug"]}/survey_summary.md

ìœ„ ìœ„ì¹˜ì— survey_summary.mdë¥¼ ìƒì„±í•˜ì„¸ìš”.
ì™„ë£Œ í›„ ê²°ê³¼ JSON ë°˜í™˜: {{"success": true, "slug": "{paper['slug']}"}}
"""
    ))

# ëª¨ë“  Task ê²°ê³¼ ìˆ˜ì§‘
results = await gather(tasks)
```

### Step 7: Registry ì—…ë°ì´íŠ¸ (ë©”ì¸ì—ì„œ ì§ì ‘)

> **ì¤‘ìš”**: `registry.json`ê³¼ `registry-index.txt` ë‘ íŒŒì¼ì„ **ë°˜ë“œì‹œ ë™ì‹œì—** ì—…ë°ì´íŠ¸í•´ì•¼ í•©ë‹ˆë‹¤.
> ë™ê¸°í™”ê°€ ì–´ê¸‹ë‚˜ë©´ ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨ ë˜ëŠ” ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œìƒ.

```python
# 1. registry.json ë¡œë“œ (ì—…ë°ì´íŠ¸ìš© - ì´ë•Œë§Œ ì „ì²´ íŒŒì¼ ì½ìŒ)
registry = Read("plugins/vehicle-contamination-or/private/registry.json")
today = datetime.now().strftime("%Y-%m-%d")

# 2. ì„±ê³µí•œ ë…¼ë¬¸ ìˆ˜ì§‘
new_ids = []
for paper in papers_to_process:
    if paper_succeeded(paper):
        new_entry = {
            "id": paper["id"],
            "slug": paper["slug"],
            "title": paper["title"],
            "year": paper["year"],
            "url": paper["url"],
            "citations": paper["citations"],
            "status": "processed",
            "added": today,
            "tags": [],
            "has_pdf": True,
            "has_code": False,
            "is_survey": paper["is_survey"]
        }
        registry["papers"].append(new_entry)
        new_ids.append(paper["id"])  # indexìš© ID ìˆ˜ì§‘

# 3. registry.json ì €ì¥
registry["last_updated"] = today
Write(
    "plugins/vehicle-contamination-or/private/registry.json",
    json.dumps(registry, indent=2, ensure_ascii=False)
)

# 4. registry-index.txtì— ìƒˆ ID ì¶”ê°€ (append)
index_content = Read("plugins/vehicle-contamination-or/private/registry-index.txt")
for new_id in new_ids:
    index_content += f"\n{new_id}"
Write(
    "plugins/vehicle-contamination-or/private/registry-index.txt",
    index_content.strip() + "\n"  # ë§ˆì§€ë§‰ ì¤„ë°”ê¿ˆ ë³´ì¥
)

# 5. ë™ê¸°í™” ê²€ì¦ (ì„ íƒì )
assert len(registry["papers"]) == len([l for l in index_content.split("\n") if l.strip() and not l.startswith("#")])
```

#### ë™ê¸°í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] registry.jsonì— ìƒˆ ë…¼ë¬¸ ì¶”ê°€ë¨
- [ ] registry-index.txtì— ìƒˆ ID ì¶”ê°€ë¨
- [ ] ë‘ íŒŒì¼ì˜ ë…¼ë¬¸ ìˆ˜ê°€ ì¼ì¹˜í•¨

### Step 8: ìµœì¢… ë³´ê³ 

```markdown
## âœ… Paper Research ì™„ë£Œ

### ê²€ìƒ‰ ì •ë³´
- ì¿¼ë¦¬: {query}
- ì¹´í…Œê³ ë¦¬: {categories}

### ì²˜ë¦¬ ê²°ê³¼
| # | ID | ì œëª© | ì—°ë„ | ìœ í˜• | ìƒíƒœ |
|---|-----|------|------|------|------|
| 1 | arxiv:2503.00952 | A Survey on... | 2025 | Survey | âœ… |
| 2 | arxiv:1901.07884 | CORAL... | 2019 | ì¼ë°˜ | âœ… |
...

### í†µê³„
- ê²€ìƒ‰ ê²°ê³¼: {total}ê°œ
- ì¤‘ë³µ ì œê±°: {duplicates}ê°œ
- ì²˜ë¦¬ ì™„ë£Œ: {success}ê°œ
- ì‹¤íŒ¨: {failed}ê°œ

### ì €ì¥ ìœ„ì¹˜
- Registry: plugins/vehicle-contamination-or/private/registry.json
- Index: plugins/vehicle-contamination-or/private/registry-index.txt
- ë…¼ë¬¸: plugins/vehicle-contamination-or/private/paper/{slug}/
```

---

## ì˜µì…˜

| ì˜µì…˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `--limit` | 5 | ì²˜ë¦¬í•  ë…¼ë¬¸ ê°œìˆ˜ |
| `--categories` | cs.CV,cs.LG,cs.AI | arXiv ì¹´í…Œê³ ë¦¬ í•„í„° |
| `--survey-only` | false | Survey ë…¼ë¬¸ë§Œ ê²€ìƒ‰ |

## ì˜ˆì‹œ

```bash
# ê¸°ë³¸ ê²€ìƒ‰
/paper-research ordinal regression --limit 5

# Surveyë§Œ ê²€ìƒ‰
/paper-research ti:"survey" ordinal regression --limit 3

# íŠ¹ì • ë„ë©”ì¸
/paper-research "ordinal regression" "age estimation" --limit 5

# ì¹´í…Œê³ ë¦¬ ì§€ì •
/paper-research ordinal regression --categories cs.CV --limit 10
```

---

## ë³‘ë ¬ ì²˜ë¦¬ ì°¸ê³ 

- **ìµœëŒ€ ë³‘ë ¬ ìˆ˜**: 10ê°œ (Claude Code ì œí•œ)
- **10ê°œ ì´ˆê³¼ ì‹œ**: ìë™ íì‰
- **ì—ëŸ¬ í•¸ë“¤ë§**: ê°œë³„ Task ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ Task ê³„ì† ì§„í–‰

---

## ğŸ¯ Project Context

ì°¨ëŸ‰ ì˜¤ì—¼ë„(Lv1~Lv4) ë¶„ë¥˜ë¥¼ ìœ„í•œ **Ordinal Regression** ê¸°ë²• íƒìƒ‰ìš©.
íŒŒì´í”„ë¼ì¸: Car Part Detection â†’ ë¶€ìœ„ë³„ OR â†’ Threshold íŒì • â†’ ì„¸ì°¨ ê¶Œì¥
